# Deep_Learning

## Description

Solution of deep learning projects.

### Lab 1-3 - Neural Networks, Convolutions and Pytorch

Firstly, we worked on scalar backpropagation only by numpy and math. And we trained on a small dataset - synth dataset to show the inefficiency.

Then, we implemented Tensor backpropagation with MNIST dataset to do the image classification.
#### Problems and Solutions
- [Main Problem statement](assignment1/assignment_1.pdf),  [Solution](assignment1/qgo500_assignment1.pdf), [Code](assignment1/qgo500_assignment1.ipynb)

Furthermore, we worked on custom Automatic differentiation to fully understand how pytorch works.
#### Problems and Solutions
- [Main Problem statement](assignment2/assignment_2.pdf),  [Solution](assignment2/qgo500_assignment2.pdf), [Code](assignment2/qgo500_assignment2.ipynb)

Finally, we used pytorch to implement CNNs to do image classification.
#### Problems and Solutions
- [Main Problem statement](assignment3/assignment_3.pdf),  [Solution](assignment3/qgo500_assignment3.pdf), [Code](assignment3/qgo500_assignment3.ipynb)


### Lab 4 - Recurrent Neural Networks, Autoregressive LISTM
We explore the long-term dependency modelling capabilities of Recurrent Neural Networks (RNNs), Long Short-Term Networks (LSTMs) with Autoregressive. Additionally, we train a character-level language model on natural language text and experiment with character-by-character text generation. 
- [Main Problem statement](assignment4/assignment_4.pdf),  [Solution](assignment4/qgo500_assignment4.pdf), [Code](assignment4/qgo500_assignment4.ipynb)


### Lab 5 - Generative Models
